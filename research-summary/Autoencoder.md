Autoencoder is an unsupervised artificial neural network that learns efficiently compress and encode data and learns to reconstruct the data back from the reduced encoded representation to a representation that is as close to the original input as possible. Autoencoder are a lossy function as the reconstructed data is not replica of input data.

## Components of Autoencoder
1. **Encoder**: 
	The encoder takes an input data and transforms it into a lower-dimensional latent representation, also known as a bottleneck. The encoder learns to reduce the input dimensions and compress the input data into an encoded representaion 
 
2. **Bottleneck**:
	The bottleneck is the lower-dimension latent output of the encoder. It is compressed form of input.

3. **Decoder**:
	The decoder takes the latent representation and reconstructs the original input data. The decoder learns to reconstruct the data from the encoded representation i.e. bottleneck to be as close to the original input as possible.

4. **Reconstruction** **Loss**:
	The reconstruction loss is the difference between the original data and reconstructed data. This ensures how well the model is performing. 

The idea is that the encoder learns a compressed representation of the input data, while the decoder learns to reconstruct the original data from the compressed representation. The goal is to minimize the reconstruction error between the input and the output.


## Model Architecture // Topic?
The autoencoder is implemented in following steps:

#### Data Preprocessing
The data used for this model is acquired from CICIDS-2017 dataset. The normal traffic data from the dataset is used for training of the model so separation is done. 
- Conversion of 1D data into 2D images:
	Using the algorithm(link) descibed above the 1D data is conveted into 2D image of dimension of $9 \times 9$.
- Increasing dimension of images by rotation and concatination:
	The 2D image's dimension is incresed from $9 \times 9$ to $18 \times 18$. The $9 \times 9$ images is rotated by 90 degrees then concatenated to original image making dimension $9 \times 18$. Another two rotated instance of image, one by 180 degress and another by 270 degress was concatenated giving us another $9 \times 18$ image. Then, the two image of dimention $9 \times 18$ is concatenated yeilding $18 \times 18$ image.
	
$$I_{18 \times 18} = I1_{9 \times 18}\ +\ I2_{9 \times 18}$$
$$where, I1_{9\times18} = OriginalImg_{9\times9}\ +\ Rotaion_{90^\degree}(OriginalImg_{9\times9})$$

$$I2_{9\times18} = Roataion_{180^\degree}(OriginalImg_{9\times9})\ +\ Rotaion_{270^\degree}(OriginalImg_{9\times9})$$

- Increasing dimension by using padding:
	For proper model creation the dimension of image is increased from $18 \times 18$ to $19  \times 19$. The padding across the bottom border and right border is performed.

#### Model Architecture
The autoencoder consists of two networks an encoder and a decoder. 

The encoder consists of two convolution blocks. Each convolution block consists of 2D-convolution layer, batch normalization layer and an activation layer. The 2D-convolution operation is performed in convolution layer with trainable filters. The batch normalization layer performs normalization by making mean and variance of batch equal to 0 and 1 respectively. This will make the training faster and more stable. The activation function introduces non linearity in the output of neuron. ## The activation function used is relu. The images of dimension $19 \times 19$ is given as a input to the autoencoder. The first layer of convolution block has 1 input channel and TODO XX output channel. The second layer of convolution block has TODO XX input channel and TODO XX output channel.

The decoder also consists of two convolution blocks. Each convolution block consists of 2D-deconvolution layer, batch normalization and an activation function. The decoder takes an input which is latent space generated by encoder. ## The activation function used is relu. The first layer of convolution block has TODO XX input channel and TODO XX output channel. The second layer of convolution block has TODO XX input channel and 1 output channel.

If x is the input image 'x' then output of encoder is y and output of decoder is x.

$$x = A_{dec}(y)$$

$$where, y = A_{enc}(x)$$
> TODO  Add image At begining or end need to decide


### Training Formulation // Tense to be used ??
Only the normal Traffic data is used for training purposes. Total dataset consists of TODO XX data in which normal traffic data is TODO XX. The 70-30 split was performed, 70 for training and 30 for testing. Again for validation 80-20 split was performed in training dataset.
Total 300 TODO CHANGE Epoch was carried out in training. The optimizer used was ADAM with learining rate 0.001 and decay $1 \times 10^{-5}$. 
- Loss calculation:
	The difference of the original image and reconstructed image is calculated which gives error of each pixel. 
	
$$Er_{19 \times 19} = OriginalImg_{19 \times 19} - ReconstructedImg_{19 \times 19}$$ 
	The two loss function?? root of sum of squared error and sum of absoute error is used.
1. Root of Sum of Squared error
	It is calculated by squaring the error and adding all the error and taking the square root.
	$$e_{rse} = \sqrt{\sum_{i=0}^N \sum_{j=0}^M {Er_{i,j}^2}}\quad, where\ N=19\ and\ M=19$$
2. Sum of Absolute error
	It is calculated by taking absoute of the error and adding the error.
	$$e_{sae} = \sum_{i=0}^N \sum_{j=0}^M {|Er_{i,j}|}\quad, where\ N=19\ and\ M=19$$
   